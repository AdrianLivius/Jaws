{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83581e66-88e7-47c4-b45d-32ddff626bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f3ee4-7451-456a-b2c1-fe2550ac3daf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_image_dir = './Jaws_labeled_images'\n",
    "train_image_dir = '/blue/bsc4892/adrian.l/Jaws_augmented_images'\n",
    "valid_image_dir = '/blue/bsc4892/adrian.l/Jaws/Jaws_valiation_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627fb20-edef-4e89-ae40-21897306892c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input image dimensions, etc.\n",
    "resized_height = 224\n",
    "resized_width = 224\n",
    "num_channel = 3 \n",
    "num_classes = 18\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daaab87-aa6e-4f39-bc9d-c15979aa1016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load train images while making everything into 1 batch\n",
    "#import os\n",
    "\n",
    "# data_dir = './Jaws_labeled_images/*'\n",
    "# num_images = len(os.listdir(data_dir))\n",
    "\n",
    "train_images = image_dataset_from_directory(\n",
    "    train_image_dir, labels='inferred', label_mode='categorical',\n",
    "     color_mode='rgb', image_size=(resized_height ,\n",
    "    resized_width ), batch_size=batch_size, shuffle=True, seed=42,\n",
    "    interpolation='bilinear', follow_links=False,\n",
    "    crop_to_aspect_ratio=False)\n",
    "print(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e801caad-5579-44be-9870-adf1d592fd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_images = image_dataset_from_directory(\n",
    "    valid_image_dir, labels='inferred', label_mode='categorical',\n",
    "     color_mode='rgb', image_size=(resized_height ,\n",
    "    resized_width ), batch_size=32, shuffle=True, seed=42,\n",
    "    interpolation='bilinear', follow_links=False,\n",
    "    crop_to_aspect_ratio=False)\n",
    "print(valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e44b3b-0d30-435c-8ee3-8bfd77fddad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note that the images have been loaded with 3 color channels!\n",
    "class_names = train_images.class_names\n",
    "print(class_names)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_images.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    #plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "    print(images[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6e5978-c513-4518-a06d-bfb16d19de37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize empty lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over the dataset to extract images and labels\n",
    "for image_batch, label_batch in train_images:\n",
    "    images.append(image_batch.numpy())\n",
    "    labels.append(label_batch.numpy())\n",
    "\n",
    "# Concatenate the lists of images and labels\n",
    "image_array = np.concatenate(images, axis=0)\n",
    "label_array = np.concatenate(labels, axis=0)\n",
    "\n",
    "print(\"Images shape:\", image_array.shape)  # Output: (88, 224, 224, 3)\n",
    "print(\"Labels shape:\", label_array.shape)  # Output: (88, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ca81c-82e0-48b2-bd1d-7b6b5cbcf2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60b049e-f255-48bb-bceb-5890be8fc6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# def augment_images(image, label):\n",
    "#     image = datagen.random_transform(image)\n",
    "#     return image, label\n",
    "# input_shape = (224, 224, 3)\n",
    "\n",
    "# augmented_dataset = train_images.map(augment_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1967ed-539d-48dc-bcd3-2bf9beb66deb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # test script with one image\n",
    "# img = load_img('./Jaws_labeled_images/Carcharhinidae/IMG_0180_Large.png')\n",
    "# x = img_to_array(img)\n",
    "# x = x.reshape((1,) + x.shape)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e1671a-de31-4457-8940-a8fb3ef3f6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented_images = datagen.flow(image_array)\n",
    "\n",
    "for i in range(10):\n",
    "    augmented_image = next(augmented_images)[0]  # Retrieve the augmented image from the generator\n",
    "    plt.imshow(augmented_image.astype('uint8')) # Plot the augmented image\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a372f-f4c6-419a-9955-e0a712a2cd80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # Reshape the image to (1, height, width, channels) for the datagen.flow() method\n",
    "# # image = np.expand_dims(x, axis=0)\n",
    "\n",
    "# # Generate augmented images indefinitely\n",
    "# augmented_images = datagen.flow(image_array, label_array)\n",
    "\n",
    "# x, y = next(augmented_images)\n",
    "# print(x.shape, y.shape)\n",
    "# # fig, ax = plt.subplots(nrows=4, ncols=8)\n",
    "# for i in range(batch_size):\n",
    "#     image = x[i]\n",
    "# #     ax.flatten()[i].imshow(np.squeeze(image))\n",
    "#     plt.imshow(image.astype('uint8'))\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673428f-e7f9-42ad-bba8-39e74ad52032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "augmented_images = datagen.flow(image_array, label_array)\n",
    "\n",
    "x, y = next(augmented_images)\n",
    "\n",
    "num_rows = 4\n",
    "num_cols = 8\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 10))\n",
    "\n",
    "for i in range(batch_size):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    augmented_image = x[i]\n",
    "    axes[row, col].imshow(augmented_image.astype('uint8'))  # Plot the augmented image\n",
    "    axes[row, col].axis('off')  # Turn off axis labels\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a16ad7-def1-457f-a55b-80f68f985e62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize arrays to store generated images and labels\n",
    "generated_images = []\n",
    "generated_labels = []\n",
    "\n",
    "\n",
    "num_batches = 100\n",
    "\n",
    "for _ in range(num_batches):\n",
    "    x_batch, y_batch = next(augmented_images)\n",
    "    generated_images.extend(x_batch)\n",
    "    generated_labels.extend(y_batch)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "generated_images = np.array(generated_images)\n",
    "generated_labels = np.array(generated_labels)\n",
    "\n",
    "# Verify the shape of generated data\n",
    "print(\"Shape of generated images:\", generated_images.shape)\n",
    "print(\"Shape of generated labels:\", generated_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca9588-3406-44be-9f72-72dc1b5cba36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.imshow(generated_images[i].astype('uint8')) # Plot the augmented image\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d3f51-359f-484b-87c5-418b2116e36c",
   "metadata": {},
   "source": [
    "## CNN on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0cd5a8-2b28-463f-835e-0a2e74609f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax') \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a20133-708b-48da-aa82-cd88de977f23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70a98d-02d9-436d-8547-822cbeb62e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Load the training dataset \n",
    "train_images = image_dataset_from_directory(\n",
    "    original_image_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,  \n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "\n",
    "# Load validation dataset\n",
    "val_ds = image_dataset_from_directory(\n",
    "    original_image_dir,\n",
    "    validation_split=0.2,  \n",
    "    subset=\"validation\",\n",
    "    seed=42,  \n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',  \n",
    "    shuffle=True  \n",
    ")\n",
    "\n",
    "# Ensure the train_images dataset is suitable for model training\n",
    "train_images = train_images.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e16a0-4e31-4eb6-a9a8-36305329c93a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images,  \n",
    "    epochs=10,  \n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772c598-8cba-4309-9d11-de5bbf1d798e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "print(\"Validation accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e4ec39-9976-4d12-80aa-f992d4f7cb97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Accuracy plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, 'ro', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5a2f3-a565-4185-8462-32a3925c1930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "val_predictions = model.predict(val_ds)\n",
    "val_predictions = np.argmax(val_predictions, axis=1)  # Convert probabilities to class indices\n",
    "\n",
    "# Convert one-hot encoded labels to class indices\n",
    "true_labels = np.concatenate([y.numpy() for _, y in val_ds])\n",
    "true_labels = np.argmax(true_labels, axis=1)  # Convert from one-hot to class indices\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_mat = confusion_matrix(true_labels, val_predictions)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d96402-ad20-409c-b0e9-fec660fd814d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helpers_plot_history import plot_history\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c6d65-b0eb-43ca-a769-cd915836cc1a",
   "metadata": {},
   "source": [
    "## CNN on augmented images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089507f-902d-471e-9070-6c08eab0d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same model but augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df626d-470d-4cbf-b90c-aa8f355d0570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the training dataset \n",
    "train_images = image_dataset_from_directory(\n",
    "    train_image_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,  \n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "\n",
    "# Load validation dataset\n",
    "val_ds = image_dataset_from_directory(\n",
    "    valid_image_dir,\n",
    "    validation_split=0.2,  \n",
    "    subset=\"validation\",\n",
    "    seed=42,  \n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',  \n",
    "    shuffle=True  \n",
    ")\n",
    "\n",
    "# Ensure the train_images dataset is suitable for model training\n",
    "train_images = train_images.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb9bde5-94bb-456a-a790-36106e639e6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    filtered_train_images,  \n",
    "    epochs=10,  \n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cebc86-20a5-41b2-9814-0e98305dffea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "print(\"Validation accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e97e3-3d09-4447-acad-a5d066ca6092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb553b0-6304-4b1a-b6ce-0840dbaba5ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_predictions = model.predict(val_ds)\n",
    "val_predictions = np.argmax(val_predictions, axis=1)  # Convert probabilities to class indices\n",
    "\n",
    "# Convert one-hot encoded labels to class indices\n",
    "true_labels = np.concatenate([y.numpy() for _, y in val_ds])\n",
    "true_labels = np.argmax(true_labels, axis=1)  # Convert from one-hot to class indices\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_mat = confusion_matrix(true_labels, val_predictions)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561fe1b-8c3d-40ff-bc98-8035c909e1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15e7af47-8e9b-438d-8e80-c25ec98cdf0f",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e92d7-bc28-4ef1-9277-bef34cde4df6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a5966-245e-435c-b48c-1ac69ed88e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a1db9-da89-4000-b150-762bc1ca3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base MobileNetV2 model with weights pre-trained on ImageNet\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0753cd-f60c-4696-932a-3a788c5978cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model on top\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6fe0e-1d92-4bb7-a2c1-10238ed79af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9269c6b-b004-49a3-9e69-9f30823e0cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "train_images = image_dataset_from_directory(\n",
    "    train_images,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    valid_images,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Prefetch data\n",
    "train_images = train_images.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6249c59-91c9-4ada-ac5c-83a829f63f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225be2fb-9c8a-4e10-8c60-47caf288e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "print(\"Validation accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c2ffb-d144-4114-ac9e-104ae6c6f8c9",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3f02b-f451-4879-a5f5-174e354d669d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c32e4-9f30-45d1-886c-cceecfc91a84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the base ResNet50 model with weights pre-trained on ImageNet\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5658555-2f5c-4806-b343-d2b0890e1816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new model on top\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994391ad-0acd-4f4c-a8f2-de7ea1d24724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed4e35-4001-40ee-88b9-95785576ffe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "train_images = image_dataset_from_directory(\n",
    "    train_images,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    valid_images,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Prefetch data\n",
    "train_images = train_images.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edfa9fb-b7ce-4e2e-9cad-b8822bfda9af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images,\n",
    "    epochs=20,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d9bc8b-ad21-4826-b2dd-b9972ed18f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "print(\"Validation accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f282b8-000e-4fdc-9d61-d7ad87b971a8",
   "metadata": {},
   "source": [
    "## VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f82de-dd2e-4c33-af2f-b0283cf2bbc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eb30aa-2d5d-4513-ba10-2412da06b769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b29c1-2101-4590-9c1f-7de13bac355c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Replace num_classes with your actual number of classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d5fe1-f89f-45b0-bbdf-b93f91160973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e10ea55-1770-4152-900a-719cf5c328ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "train_images = image_dataset_from_directory(\n",
    "    train_images,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    valid_images,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Prefetch data\n",
    "train_images = train_images.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a25ce-f695-4c43-913a-7f5a0fff50ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_images,\n",
    "    epochs=20,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bd4114-da94-4b4f-aa30-a3f1ba895cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_ds)\n",
    "print(\"Validation loss:\", val_loss)\n",
    "print(\"Validation accuracy:\", val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95e1105-ea84-4a9d-babf-3e1190b7f4c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f0765-af1c-43b6-b7b4-dae730abe3b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import UpSampling2D, Input, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4011bb-e384-4143-8c51-b9df342c19b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the encoder part of the autoencoder\n",
    "input_img = Input(shape=(224, 224, 3))  # Adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eab0720-ff4d-4d82-a1af-be6bc26df3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Define the decoder part of the autoencoder\n",
    "x = Conv2DTranspose(128, (3, 3), strides=2, activation='relu', padding='same')(encoded)\n",
    "x = Conv2DTranspose(64, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "x = Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b39793a-bd49-4f21-abd7-6bba443984eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load your data\n",
    "train_images = image_dataset_from_directory(\n",
    "    original_image_dir,\n",
    "    label_mode=None,  # No labels needed as this is unsupervised\n",
    "    color_mode='rgb',\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d485c-1a5e-4dea-9f94-2b2cda659e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize images to [0, 1] to match the sigmoid activation in the decoder output\n",
    "normalized_images = train_images.map(lambda x: (x / 255.0, x / 255.0))  # Set x as both input and target\n",
    "normalized_images = normalized_images.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22524b2-c8f8-4895-b1d4-b22effe97efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the autoencoder\n",
    "history = autoencoder.fit(\n",
    "    normalized_images,\n",
    "    epochs=50,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33221fd-380c-47c5-ae97-eab873d8a0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss = autoencoder.evaluate(normalized_images)\n",
    "print(\"Validation Loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db3908-3f45-44d6-a970-2044d8a7c51f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f063ac-1b94-49a9-8665-833bca8c800d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd25f36-48d9-4a1f-91f9-a537e01098cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81313a-1a69-4d6a-aeb0-168717450e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9dc21-367b-4b10-93d7-c9602b4d4782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6502dd17-572c-4a0a-b8b9-4509e35887bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f24d5a-44c8-4abd-a00a-7afc8db3a2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3aefd847-26ca-4873-84fe-1e12312e718f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a908c3b-6ce4-4e0e-8d1f-40430b155ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Flatten,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# CNNs are more concise and have fewer parameteres than dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95192a97-faf2-4a8d-b34e-0b0901cee06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc23f314-b515-4f35-8528-c54043e1fbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the generator on the training data\n",
    "datagen.fit(image_array)\n",
    "\n",
    "# Compile the new model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a2b77-a603-467e-be4a-de19884ac7c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    patience=5,          # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_images,  \n",
    "    epochs=10,  \n",
    "    validation_data=valid_images,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f94bf-77ab-4162-b609-376df1a508fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from helpers_plot_history import plot_history\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793af197-b630-4793-a26a-30c415a25441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history= model.fit(augmented_images,\n",
    "          epochs=20,\n",
    "#          steps_per_epoch=4,\n",
    "          validation_data=valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e405bd-eec3-47ef-ad5b-60137b2720c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0da25-f678-4644-a854-b0f6402b96fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80cf532f-283f-4734-9e7a-2b95aae492a5",
   "metadata": {},
   "source": [
    "# Below are test scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdab97e-8c5c-4e96-b653-1ad337cfc39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define an ImageDataGenerator with augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load a sample image\n",
    "image = np.random.random((224, 224, 3))\n",
    "\n",
    "# Reshape the image to (1, height, width, channels) for the datagen.flow() method\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# Generate augmented images indefinitely\n",
    "augmented_images = datagen.flow(image)\n",
    "\n",
    "# Specify how many augmented images you want to generate\n",
    "num_images_to_generate = 5\n",
    "\n",
    "# Generate and plot the specified number of augmented images\n",
    "for i in range(num_images_to_generate):\n",
    "    augmented_image = next(augmented_images)[0]  # Retrieve the augmented image from the generator\n",
    "    plt.imshow(augmented_image.astype('uint8'))  # Plot the augmented image\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8968e2a-1efb-4bf5-aeba-1ebe74ac3d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define an ImageDataGenerator with augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load a sample image\n",
    "image = np.random.random((224, 224, 3))\n",
    "\n",
    "# Reshape the image to (1, height, width, channels) for the datagen.flow() method\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# Generate augmented images indefinitely\n",
    "augmented_images = datagen.flow(image)\n",
    "\n",
    "# Generate and plot 32 augmented images in an 8x4 grid plot\n",
    "num_images_to_generate = 32\n",
    "num_rows = 8\n",
    "num_cols = 4\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 30))\n",
    "\n",
    "for i in range(num_images_to_generate):\n",
    "    row = i // num_cols\n",
    "    col = i % num_cols\n",
    "    augmented_image = next(augmented_images)[0]  # Retrieve the augmented image from the generator\n",
    "    axes[row, col].imshow(augmented_image.astype('uint8'))  # Plot the augmented image\n",
    "    axes[row, col].axis('off')  # Turn off axis labels\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec8f90-7024-47a3-b0ed-d433ec627e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
